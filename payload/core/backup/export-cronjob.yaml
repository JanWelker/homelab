---
# ConfigMap with backup script
apiVersion: v1
kind: ConfigMap
metadata:
  name: backup-script
  namespace: backup
data:
  backup.sh: |
    #!/bin/bash
    set -euo pipefail

    # Configuration
    BACKUP_ROOT="/backup"
    RETENTION_DAYS="${RETENTION_DAYS:-90}"
    DATE=$(date +%Y-%m-%d-%H-%M-%S)

    echo "=== Backup Export Started at $(date) ==="

    # Namespaces to backup (all namespaces if not specified)
    if [ -z "${BACKUP_NAMESPACES:-}" ]; then
      NAMESPACES=$(kubectl get namespaces -o jsonpath='{.items[*].metadata.name}')
    else
      NAMESPACES="${BACKUP_NAMESPACES}"
    fi

    for NS in $NAMESPACES; do
      if [ "$NS" = "backup" ]; then
        continue
      fi
      echo "Processing namespace: $NS"
      BACKUP_DIR="${BACKUP_ROOT}/${NS}/${DATE}"
      mkdir -p "$BACKUP_DIR"
      
      # Get all PVCs in namespace
      PVCS=$(kubectl get pvc -n "$NS" -o jsonpath='{.items[*].metadata.name}' 2>/dev/null || echo "")
      
      for PVC in $PVCS; do
        SC=$(kubectl get pvc "$PVC" -n "$NS" -o jsonpath='{.spec.storageClassName}')
        TARGET="${TARGET_STORAGE_CLASS:-rook-ceph-block}"
        if [ "$SC" != "$TARGET" ]; then
           # minimal log to avoid spam
           # echo "  Skipping $PVC ($SC != $TARGET)"
           continue
        fi
        
        echo "  Backing up PVC: $PVC"
        SNAPSHOT_NAME="${NS}-${PVC}-${DATE}"
        
        # Create snapshot
        cat <<EOF | kubectl apply -f -
    apiVersion: snapshot.storage.k8s.io/v1
    kind: VolumeSnapshot
    metadata:
      name: ${SNAPSHOT_NAME}
      namespace: ${NS}
    spec:
      volumeSnapshotClassName: csi-rbdplugin-snapclass
      source:
        persistentVolumeClaimName: ${PVC}
    EOF
        
        # Wait for snapshot to be ready
        echo "  Waiting for snapshot to be ready..."
        for i in {1..60}; do
          READY=$(kubectl get volumesnapshot "$SNAPSHOT_NAME" -n "$NS" -o jsonpath='{.status.readyToUse}' 2>/dev/null || echo "false")
          if [ "$READY" = "true" ]; then
            echo "  Snapshot ready!"
            break
          fi
          sleep 5
        done
        
        # Create temporary PVC from snapshot
        TEMP_PVC="${SNAPSHOT_NAME}-restore"
        STORAGE_CLASS=$(kubectl get pvc "$PVC" -n "$NS" -o jsonpath='{.spec.storageClassName}')
        SIZE=$(kubectl get pvc "$PVC" -n "$NS" -o jsonpath='{.spec.resources.requests.storage}')
        
            cat <<EOF | kubectl apply -f -
    apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      name: ${TEMP_PVC}
      namespace: ${NS}
    spec:
      storageClassName: ${STORAGE_CLASS}
      dataSource:
        name: ${SNAPSHOT_NAME}
        kind: VolumeSnapshot
        apiGroup: snapshot.storage.k8s.io
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: ${SIZE}
    EOF
        
        # Wait for PVC to be bound
        echo "  Waiting for restore PVC..."
        for i in {1..60}; do
          STATUS=$(kubectl get pvc "$TEMP_PVC" -n "$NS" -o jsonpath='{.status.phase}' 2>/dev/null || echo "Pending")
          if [ "$STATUS" = "Bound" ]; then
            echo "  Restore PVC bound!"
            break
          fi
          sleep 5
        done
        
        # Create data mover pod
        MOVER_POD="${SNAPSHOT_NAME}-mover"
        echo "  Starting data mover pod: ${MOVER_POD}"
        
        cat <<EOF | kubectl apply -f -
    apiVersion: v1
    kind: Pod
    metadata:
      name: ${MOVER_POD}
      namespace: ${NS}
    spec:
      restartPolicy: Never
      securityContext:
        runAsUser: 0  # Run as root for NFS write
      containers:
      - name: mover
        image: alpine:latest
        command: ["/bin/sh", "-c"]
        args:
          - |
            echo "Starting backup of ${PVC}..."
            mkdir -p /backup/${NS}/${DATE}
            # Archive data to NFS
            tar czf /backup/${NS}/${DATE}/${PVC}.tar.gz -C /restore .
            echo "Backup complete!"
        volumeMounts:
        - name: restore
          mountPath: /restore
          readOnly: true
        - name: backup
          mountPath: /backup
      volumes:
      - name: restore
        persistentVolumeClaim:
          claimName: ${TEMP_PVC}
      - name: backup
        nfs:
          server: ${NFS_SERVER}
          path: ${NFS_PATH}
    EOF
        
        # Wait for mover pod to finish
        echo "  Waiting for data copy..."
        for i in {1..300}; do # 25 minutes timeout
          PHASE=$(kubectl get pod "$MOVER_POD" -n "$NS" -o jsonpath='{.status.phase}' 2>/dev/null || echo "Unknown")
          if [ "$PHASE" = "Succeeded" ]; then
            echo "  Data copy succeeded!"
            break
          elif [ "$PHASE" = "Failed" ]; then
            echo "  Data copy FAILED!"
            kubectl logs "$MOVER_POD" -n "$NS" || true
            break # Proceed to cleanup but log error
          fi
          sleep 5
        done
        
        # Cleanup
        kubectl delete pod "$MOVER_POD" -n "$NS" --ignore-not-found=true
        kubectl delete pvc "$TEMP_PVC" -n "$NS" --ignore-not-found=true
        
        echo "  Snapshot ${SNAPSHOT_NAME} backed up to NFS"
      done
    done

    # Cleanup old backups and snapshots
    echo "Cleaning up backups older than ${RETENTION_DAYS} days..."
    find "${BACKUP_ROOT}" -type d -mtime +${RETENTION_DAYS} -exec rm -rf {} + 2>/dev/null || true

    # Cleanup old snapshots
    for NS in $NAMESPACES; do
      if [ "$NS" = "backup" ]; then continue; fi
      OLD_SNAPSHOTS=$(kubectl get volumesnapshots -n "$NS" -o jsonpath='{.items[*].metadata.name}' 2>/dev/null || echo "")
      for SNAP in $OLD_SNAPSHOTS; do
        CREATED=$(kubectl get volumesnapshot "$SNAP" -n "$NS" -o jsonpath='{.metadata.creationTimestamp}')
        CREATED_EPOCH=$(date -d "$CREATED" +%s 2>/dev/null || date -j -f "%Y-%m-%dT%H:%M:%SZ" "$CREATED" +%s 2>/dev/null || echo "0")
        NOW_EPOCH=$(date +%s)
        AGE_DAYS=$(( (NOW_EPOCH - CREATED_EPOCH) / 86400 ))
        if [ "$AGE_DAYS" -gt "$RETENTION_DAYS" ]; then
          echo "  Deleting old snapshot: $SNAP (${AGE_DAYS} days old)"
          kubectl delete volumesnapshot "$SNAP" -n "$NS" --ignore-not-found=true
        fi
      done
    done

    echo "=== Backup Export Completed at $(date) ==="
---
# CronJob for daily backup
apiVersion: batch/v1
kind: CronJob
metadata:
  name: pvc-backup
  namespace: backup
spec:
  schedule: "0 3 * * *" # 3 AM daily
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 3
  jobTemplate:
    spec:
      backoffLimit: 2
      template:
        spec:
          serviceAccountName: backup-exporter
          restartPolicy: OnFailure
          containers:
            - name: backup
              securityContext:
                runAsUser: 0
              image: bitnami/kubectl:latest
              command: ["/bin/bash", "/scripts/backup.sh"]
              env:
                - name: RETENTION_DAYS
                  value: "90"
                - name: TARGET_STORAGE_CLASS
                  value: "rook-ceph-block"
                - name: NFS_SERVER
                  value: "bsnas1.somuch.cloud"
                - name: NFS_PATH
                  value: "/mnt/data/k8s/backup"
              volumeMounts:
                - name: backup-storage
                  mountPath: /backup
                - name: backup-script
                  mountPath: /scripts
          volumes:
            - name: backup-storage
              persistentVolumeClaim:
                claimName: backup-storage
            - name: backup-script
              configMap:
                name: backup-script
                defaultMode: 0755
