# yaml-language-server: $schema=https://raw.githubusercontent.com/argoproj/argo-cd/master/manifests/crds/application-crd.yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: rook-ceph-cluster
  namespace: argocd
  annotations:
    argocd.argoproj.io/sync-wave: "-1" # Deploy after operator
    link.argocd.argoproj.io/external-link: https://rook.infra.k8s.wlkr.ch
spec:
  project: default
  source:
    repoURL: https://charts.rook.io/release
    chart: rook-ceph-cluster
    targetRevision: v1.16.1
    helm:
      valuesObject:
        operatorNamespace: rook-ceph

        # Toolbox for debugging (optional, useful for troubleshooting)
        toolbox:
          enabled: true

        # Ingress removed - using Gateway API HTTPRoute instead

        # CephCluster configuration
        cephClusterSpec:
          monitoring:
            enabled: true
          dataDirHostPath: /var/lib/rook

          # HA: 3 mons, 2 mgrs
          mon:
            count: 3
            allowMultiplePerNode: false
          mgr:
            count: 2
            allowMultiplePerNode: false

          # Dashboard (accessible via port-forward)
          dashboard:
            enabled: true
            ssl: false

          # Block device storage (partition created by Ignition)
          storage:
            useAllNodes: true
            useAllDevices: false
            config:
              osdsPerDevice: "1"
            # Use the rook-osd partition created by Ignition
            devicePathFilter: "^/dev/disk/by-partlabel/rook-osd$"

          # Resource limits for single-node
          resources:
            mon:
              requests:
                cpu: 100m
                memory: 256Mi
              limits:
                memory: 1Gi
            mgr:
              requests:
                cpu: 100m
                memory: 256Mi
              limits:
                memory: 1Gi
            osd:
              requests:
                cpu: 100m
                memory: 512Mi
              limits:
                memory: 2Gi

        # CephBlockPool for RBD volumes
        cephBlockPools:
          - name: rbd-pool
            spec:
              failureDomain: host
              replicated:
                size: 3 # Standard replication for HA
                requireSafeReplicaSize: true
            storageClass:
              enabled: true
              name: rook-ceph-block
              isDefault: true
              reclaimPolicy: Delete
              allowVolumeExpansion: true
              volumeBindingMode: Immediate
              parameters:
                imageFormat: "2"
                imageFeatures: layering
                csi.storage.k8s.io/provisioner-secret-name: rook-csi-rbd-provisioner
                csi.storage.k8s.io/provisioner-secret-namespace: rook-ceph
                csi.storage.k8s.io/controller-expand-secret-name: rook-csi-rbd-provisioner
                csi.storage.k8s.io/controller-expand-secret-namespace: rook-ceph
                csi.storage.k8s.io/node-stage-secret-name: rook-csi-rbd-node
                csi.storage.k8s.io/node-stage-secret-namespace: rook-ceph
                csi.storage.k8s.io/fstype: ext4

        # Disable CephFS for now (can enable later)
        cephFileSystems: []

        # Disable Object Store for now
        cephObjectStores: []
  destination:
    server: https://kubernetes.default.svc
    namespace: rook-ceph
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true
      - ServerSideApply=true
