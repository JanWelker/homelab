---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: rook-ceph-cluster
  namespace: argocd
  annotations:
    argocd.argoproj.io/sync-wave: "-1"
    link.argocd.argoproj.io/external-link: https://rook.infra.k8s.wlkr.ch
spec:
  project: infra
  source:
    repoURL: https://charts.rook.io/release
    chart: rook-ceph-cluster
    targetRevision: v1.19.0
    helm:
      parameters:
        - name: cephClusterSpec.skipUpgradeChecks
          value: "true"
      valuesObject:
        operatorNamespace: rook-ceph

        # Toolbox for debugging (optional, useful for troubleshooting)
        toolbox:
          enabled: true

        # Ingress removed - using Gateway API HTTPRoute instead

        # CephCluster configuration
        cephClusterSpec:
          skipUpgradeChecks: true
          cephVersion:
            image: quay.io/ceph/ceph:v19.2.2
            imagePullPolicy: "Always"
          monitoring:
            enabled: true
          dataDirHostPath: /var/lib/rook

          # HA: 3 mons, 2 mgrs
          mon:
            count: 3
            allowMultiplePerNode: false
          mgr:
            count: 2
            allowMultiplePerNode: false

          # Dashboard (accessible via port-forward)
          dashboard:
            enabled: true
            ssl: false

          # Block device storage (partition created by Ignition)
          storage:
            useAllNodes: true
            useAllDevices: false
            config:
              osdsPerDevice: "1"
            # Use the rook-osd partition created by Ignition
            devicePathFilter: "^/dev/disk/by-partlabel/rook-osd$"

          # Resource limits for selected nodes
          resources:
            mon:
              requests:
                cpu: 100m
                memory: 256Mi
              limits:
                memory: 1Gi
            mgr:
              requests:
                cpu: 100m
                memory: 256Mi
              limits:
                memory: 1Gi
            osd:
              requests:
                cpu: 100m
                memory: 1Gi
              limits:
                memory: 2Gi

          placement:
            all:
              tolerations:
                - key: node-role.kubernetes.io/control-plane
                  operator: Exists
                  effect: NoSchedule

        # CephBlockPool for RBD volumes
        cephBlockPools:
          - name: rbd-pool
            spec:
              failureDomain: host
              replicated:
                size: 3
                requireSafeReplicaSize: true
            storageClass:
              enabled: true
              name: rook-ceph-block
              isDefault: true
              reclaimPolicy: Delete
              allowVolumeExpansion: true
              volumeBindingMode: Immediate
              parameters:
                imageFormat: "2"
                imageFeatures: layering
                # yamllint disable rule:line-length
                csi.storage.k8s.io/provisioner-secret-name: rook-csi-rbd-provisioner
                csi.storage.k8s.io/provisioner-secret-namespace: rook-ceph
                csi.storage.k8s.io/controller-expand-secret-name: rook-csi-rbd-provisioner
                csi.storage.k8s.io/controller-expand-secret-namespace: rook-ceph
                csi.storage.k8s.io/node-stage-secret-name: rook-csi-rbd-node
                csi.storage.k8s.io/node-stage-secret-namespace: rook-ceph
                # yamllint enable rule:line-length
                csi.storage.k8s.io/fstype: ext4

        # Disable CephFS for now (can enable later)
        cephFileSystems: []

        # Disable Object Store for now
        cephObjectStores: []
  destination:
    server: https://kubernetes.default.svc
    namespace: rook-ceph
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true
      - ServerSideApply=true
